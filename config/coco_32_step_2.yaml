MODEL:
    G_ARCHITECTURE: "NORM"
    D_ARCHITECTURE: "ALEXNET"
    G_PRETRAINED_MODEL_PATH: "./output/coco_32_finetune_5/models/G_9999.ckpt"
    D_PRETRAINED_MODEL_PATH: "./output/coco_32_finetune_5/models/D_9999.ckpt"

DATA:
    USE_DATASET: "coco"  # "cifar10", "nuswide81", "coco"
    LABEL_DIM: 80
    DB_SIZE: 117218
    TEST_SIZE: 5000
    WIDTH_HEIGHT: 32
    MAP_R: 117218
    LIST_ROOT: "./data/coco"
    DATA_ROOT: "./data/coco"
    OUTPUT_DIR: "./output/coco_32_finetune_10"

TRAIN:
    BATCH_SIZE: 128
    ITERS: 10000
    CROSS_ENTROPY_ALPHA: 10
    LR: 1e-4  # Initial learning rate
    G_LR: 0.0  # 1e-4
    DECAY: True  # Whether to decay LR over learning
    N_CRITIC: 1  # Critic steps per generator steps
    EVAL_FREQUENCY: 2000
    SAMPLE_FREQUENCY: 2000
    ACGAN_SCALE: 1.0
    ACGAN_SCALE_FAKE: 0.1
    WGAN_SCALE: 0.0  
    WGAN_SCALE_GP: 10.0
    ACGAN_SCALE_G: 0.1
    WGAN_SCALE_G: 1.0
